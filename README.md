# DS4A_team-68_project

![Coronovirus_0_0](https://user-images.githubusercontent.com/92189294/160304123-219c9b35-80c1-4b1f-9505-3b3f0702b5e6.png)


The purpose of the app is to analyze twitter data for the first 10 days of each variant. It provides 6 tabs: About, Dataframe, Sentiment, WordCloud, Heatmap, and Prediction. The About tab is an introduction page with the title and the description of the project. 

The data was obtained by using the twitter data from a publication. Once the data was downloaded, there only two columns visible: timestamp of the tweet and tweet id, which is a unique identitfier for each tweet along with the rest of its features. The tweet id was decoded before getting access to all the features else there is only the tweet id and timestamp that is available. The `twarc` module utilizes the twitter API to 'hydrate' the tweet id into features. Next, the data was sampled for the first 10 days of each variant (Beta, Delta, Omicron). Then, data is prepared by selecting the relevant variables and analysis was performed to extract the metrics needed for each tab of the app.

![Updated Datafolio](https://user-images.githubusercontent.com/92189294/168408987-9c369b70-696d-4bfc-a29c-af11649c5eff.png)


  The Dataframe tab displays the data through a criteria of filters (columns, variant, keyword, and date range). The component used for selecting columns is the function `st.multiselect()` where the user can select multiple values (columns) to click or unclick; `st.multiselect` is used instead of `st.selectbox` since a subset of the columns can exist in a dataframe. The variant also uses `st.mulitselect` since all variants exist in the dataframe. The date range utilizes a streamlit component called `st.date_input` on the column `created_at`; two `st.date_input` functions is used (one for start date and one for the end date where end date has to be larger than start date). The last component to address filter by keyword (text) is the `st.text_input`. Then, the text uses an SQL engine from the `SQLite3` module to extract rows where the `text` column contains the keyword. The next figure is a `st.selectbox` where the user can choose which visualization to display: correlation plot or scatterplot. If correlation plot is selected, a correlation heatmap is displayed from values -1 to 1. If the scatterplot is choosen, two `st.selectbox` components are generated where one represents the x-axis and the other one represents the y-axis for display of the 2D scatterplot. The list of columns to select from are `like_count`, `reply_count`, `retweet_count`, `followers_count`, `following_count`, `tweet_count`, `source`, `date`, `variant`, and `hour`.
  
  The Sentiment tab shows two figures. First is barplot across variant and sentiment. The `st.radio` button was provided for the user whether the barplot is normalized or (not) counted values. The barplot (non-normalized) lets users see how many tweets had a sentiment (positive, negative, neutral) of a given variant. The problem is the data has more tweets sampled unevenly across variants which is not good for comparison; Omicron has the most tweets sampled. The normalized barplot shows the user how frequent sentiment of the tweets are toward Covid across each variant. The second figure is a time series of sentiment score on a chosen variant aggregated by a time interval the user can select. The component used for the time interval is a `st.selectbox` with the options: 15 minutes, 30 minutes, 45 minutes, 1 hour, 2 hours. The aggregation method is the mean which addresses noise for each tweet; many 1s and -1s around a few seconds is not informative. The component used for variant selection is the `st.selectbox` where the options are Beta, Delta, and Omicron.
  
  The WorldCloud tab displays the top n frequent words which the user can select. The tool used to pick the number words is the `st.slider` from a minimum of 5 to a maximum of 150 words. Once the slider points to a value, the top-n words are shown in the word cloud. The word cloud is generate through several steps. First, clean up the tweets using `nltk` module to remove stop words, punctuations, and lower case. The functions used to generate the wordcloud are WordNetLemmatizer(), stopwords.words('english'), and polarity_scores() from `vaderSentiment` module. The first two functions were used to find the root word (apple=apples) and remove unnecessary words (the, a, and, etc.). The polarity_scores() calculates the sentiment of the tweet. Once the sentiment is provided for each tweet, the tweets are concatenated into a list of words. Next, a bag of words is created to get the frequency of each unique word. Then, the sentiment for each unique word is found by searching all tweets containing the word through a loop. Finally, take the mean of the sentmients for tweets containing the word at the end of the loop. The WordCloud function is used to generate the word cloud. The size of the word indicates how often the word is in the tweet; the larger the text, the more fruent the word is tweeted. The color is added to the text to indicate the sentiment of word on average which was calculated; green represents positive sentiment, gray represents netural sentiment, and red represents negative sentiment.    

  The Heatmap tab visualizes a heatmap of the hour across the variant. The figure would display a color intensity which is the average sentiment of tweets across a 2-D grid where the x-axis is the hour and the y-axis is the variant. There is component `st.radio` button that select either all tweets to be used in heatmap (Yes) or a subset filtered by a text (No). If the user selects 'No', a `st.selectbox` gets displayed for the user to pick one of the top 500 words to filter the data. Once the data is filtered, the heatmap is generated on that subset. This option allows the user to see the overall sentiment of tweets associated the selected word across the hour and the variant. 
   
  The prediction tab allows the user to classify the input text as either positive, negative, or neutral. It requires the user to type in the text box and press enter. The module `vaderSentiment` is used to predict the sentiment score of the text. The module is tuned for social media analysis which can take into account for emojis, exclamations, stop words, etc. There are two results: a sentiment score and the sentiment. The sentiment score ranges from -1 to 1 which tells the user how strong the sentiment is on the text along with the sentiment. For clarity to the user, the text was set a color to represent its sentiment: red for negative, green for positive, and gray for neutral. 
